{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b77cd762ecdbce0c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_sample_folder = '../data/PCA_2_4'\n",
    "input_json_folder = '../data/PCA_2_4_landmarks'\n",
    "output_folder = '../data/PCA_2_4_avg'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66acb6fc3896ca05",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "w = 170\n",
    "h = 240\n",
    "\n",
    "n = 60"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40d0951c2ebdb008",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Path(output_folder).mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a7dc2a80e9a529d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def similarity_transform(in_points, out_points):\n",
    "    s60 = np.sin(60 * np.pi / 180)\n",
    "    c60 = np.cos(60 * np.pi / 180)\n",
    "\n",
    "    in_pts = np.copy(in_points).tolist()\n",
    "    out_pts = np.copy(out_points).tolist()\n",
    "\n",
    "    xin = c60 * (in_pts[0][0] - in_pts[1][0]) - s60 * \\\n",
    "        (in_pts[0][1] - in_pts[1][1]) + in_pts[1][0]\n",
    "    yin = s60 * (in_pts[0][0] - in_pts[1][0]) + c60 * \\\n",
    "        (in_pts[0][1] - in_pts[1][1]) + in_pts[1][1]\n",
    "\n",
    "    in_pts.append([np.int32(xin), np.int32(yin)])\n",
    "\n",
    "    x_out = c60 * (out_pts[0][0] - out_pts[1][0]) - s60 * \\\n",
    "        (out_pts[0][1] - out_pts[1][1]) + out_pts[1][0]\n",
    "    y_out = s60 * (out_pts[0][0] - out_pts[1][0]) + c60 * \\\n",
    "    (out_pts[0][1] - out_pts[1][1]) + out_pts[1][1]\n",
    "\n",
    "    out_pts.append([np.int32(x_out), np.int32(y_out)])\n",
    "\n",
    "    tform = cv2.estimateAffinePartial2D(np.array([in_pts]), np.array([out_pts]))\n",
    "    \n",
    "    return tform[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ae20668e7c176f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def rect_contains(rect, point):\n",
    "    if point[0] < rect[0]:\n",
    "        return False\n",
    "    \n",
    "    elif point[1] < rect[1]:\n",
    "        return False\n",
    "    \n",
    "    elif point[0] > rect[2]:\n",
    "        return False\n",
    "    \n",
    "    elif point[1] > rect[3]:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def calculate_triangles(rect, points):\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "\n",
    "    for p in points:\n",
    "        subdiv.insert((p[0], p[1]))\n",
    "\n",
    "    triangle_list = subdiv.getTriangleList()\n",
    "    delaunay_tri = []\n",
    "\n",
    "    for t in triangle_list:\n",
    "        pt = []\n",
    "\n",
    "        pt.append((t[0], t[1]))\n",
    "        pt.append((t[2], t[3]))\n",
    "        pt.append((t[4], t[5]))\n",
    "\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "\n",
    "        if rect_contains(rect, pt1) and rect_contains(rect, pt2) and rect_contains(rect, pt3):\n",
    "            ind = []\n",
    "            \n",
    "            for j in range(0, 3):\n",
    "                for k in range(0, len(points)):\n",
    "                    if abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0:\n",
    "                        ind.append(k)\n",
    "                        \n",
    "            if len(ind) == 3:\n",
    "                delaunay_tri.append((ind[0], ind[1], ind[2]))\n",
    "\n",
    "    return delaunay_tri"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65bfecc536b5bb23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def constrain_point(p, w, h):\n",
    "    return (min(max(p[0], 0), w - 1), min(max(p[1], 0), h - 1))\n",
    "\n",
    "def apply_affine_transform(src, src_tri, dst_tri, size):\n",
    "    warp_mat = cv2.getAffineTransform(np.float32(src_tri), np.float32(dst_tri))\n",
    "\n",
    "    dst = cv2.warpAffine(src, warp_mat, (size[0], size[1]), None,\n",
    "        flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    return dst\n",
    "\n",
    "def warp_triangle(img1, img2, t1, t2):\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "\n",
    "    t1_rect = []\n",
    "    t2_rect = []\n",
    "    t2_rect_int = []\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        t1_rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
    "        t2_rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "        t2_rect_int.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "\n",
    "    mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t2_rect_int), (1.0, 1.0, 1.0), 16, 0)\n",
    "\n",
    "    img1_rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "\n",
    "    size = (r2[2], r2[3])\n",
    "\n",
    "    img2_rect = apply_affine_transform(img1_rect, t1_rect, t2_rect, size)\n",
    "    img2_rect = img2_rect * mask\n",
    "\n",
    "    img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]] = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]] * ((1.0, 1.0, 1.0) - mask)\n",
    "    img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]] = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]] + img2_rect"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c4dfbbca3fbb114",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for cluster in Path(input_sample_folder).iterdir():\n",
    "    cluster_id = cluster.name\n",
    "    cluster_photos = {}\n",
    "    for cluster_photo in cluster.glob('*.jpg'):\n",
    "        cluster_photo = cluster_photo.name\n",
    "        \n",
    "        if not (Path(input_json_folder) / cluster_photo.replace('.jpg', '.json')).exists():\n",
    "            continue\n",
    "        \n",
    "        cluster_landmarks = json.load(open(Path(input_json_folder) / cluster_photo.replace('.jpg', '.json')))\n",
    "        \n",
    "        cluster_photos[cluster_photo] = cluster_landmarks\n",
    "        \n",
    "    cluster_images = {}\n",
    "    \n",
    "    for cluster_photo, cluster_landmarks in cluster_photos.items():\n",
    "        cluster_images[cluster_photo] = {\n",
    "            'landmarks': cluster_landmarks,\n",
    "            'image': cv2.imread(str(Path(input_sample_folder) / cluster_photo))\n",
    "        }\n",
    "        \n",
    "    images_norm = []\n",
    "    landmarks_norm = []\n",
    "    \n",
    "    eyecorner_dst = [\n",
    "        (np.int32(0.3 * w), np.int32(h / 3)),\n",
    "        (np.int32(0.7 * w), np.int32(h / 3))\n",
    "    ]\n",
    "    \n",
    "    boundary_pts = np.array([\n",
    "        (0, 0), (w / 2, 0), (w - 1, 0), (w - 1, h / 2),\n",
    "        (w - 1, h - 1), (w / 2, h - 1), (0, h - 1), (0, h / 2)\n",
    "    ])\n",
    "    \n",
    "    landmarks_avg = np.array(\n",
    "        [(0, 0)] * (n + len(boundary_pts)),\n",
    "        np.float32()\n",
    "    )\n",
    "\n",
    "    for record in cluster_images:\n",
    "        image = cluster_images[record]['image']\n",
    "        landmarks = cluster_images[record]['landmarks']\n",
    "        \n",
    "        eyecorner_src = [landmarks[36], landmarks[45]]\n",
    "        tform = similarity_transform(eyecorner_src, eyecorner_dst)\n",
    "        \n",
    "        img = cv2.warpAffine(image, tform, (w, h))\n",
    "        \n",
    "        landmarks_ = np.reshape(np.array(landmarks), (68, 1, 2))\n",
    "        landmarks = cv2.transform(landmarks_, tform)\n",
    "        landmarks = np.float32(np.reshape(landmarks, (68, 2)))\n",
    "        \n",
    "        landmarks = np.append(landmarks, boundary_pts, axis=0)\n",
    "        \n",
    "        landmarks_avg = landmarks_avg + landmarks / len(cluster_images)\n",
    "\n",
    "        landmarks_norm.append(landmarks)\n",
    "        images_norm.append(img)\n",
    "        \n",
    "    rect = (0, 0, w, h)\n",
    "    tri = calculate_triangles(rect, np.array(landmarks_avg))      \n",
    "    \n",
    "    output = np.zeros((h, w, 3), np.float32())\n",
    "    \n",
    "    for i in range(0, len(images_norm)):\n",
    "        img = np.zeros((h, w, 3), np.float32())\n",
    "        for j in range(0, len(tri)):\n",
    "            t_in = []\n",
    "            t_out = []\n",
    "\n",
    "            for k in range(0, 3):\n",
    "                p_in = landmarks_norm[i][tri[j][k]]\n",
    "                p_in = constrain_point(p_in, w, h)\n",
    "\n",
    "                p_out = landmarks_avg[tri[j][k]]\n",
    "                p_out = constrain_point(p_out, w, h)\n",
    "\n",
    "                t_in.append(p_in)\n",
    "                t_out.append(p_out)\n",
    "\n",
    "            warp_triangle(images_norm[i], img, t_in, t_out)\n",
    "\n",
    "        # Add image intensities for averaging\n",
    "        output = output + img\n",
    "\n",
    "    # Divide by num_images to get average\n",
    "    output = output / len(cluster_images)\n",
    "\n",
    "    cv2.imwrite(str(Path(output_folder) / f'average_face_{cluster_id}.jpg'), 255 * output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff485777884621d9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e31f551529d0b66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
