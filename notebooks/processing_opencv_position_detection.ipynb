{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce8b7fd0bad997a2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.ioff()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4937c87957fadfe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_frontal = '../models/haarcascade_frontalface_default.xml'\n",
    "model_profile = '../models/haarcascade_profileface.xml'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e6c6965c239d60",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_parent = '../data/wiki_crop/00/'\n",
    "output_parent = '../data/wiki_crop_opencv_position_detection/'\n",
    "\n",
    "sample_frontal_face = [\n",
    "    '69300_1950-05-11_2009.jpg',\n",
    "    '196900_1884-05-20_1940.jpg',\n",
    "    '346200_1968-12-09_2005.jpg',\n",
    "    '487200_1890-12-11_1964.jpg',\n",
    "    '489500_1970-05-05_2006.jpg'\n",
    "]\n",
    "\n",
    "sample_profile_face = [\n",
    "    '23300_1962-06-19_2011.jpg',\n",
    "    '102100_1970-10-09_2008.jpg',\n",
    "    '654800_1950-01-03_1987.jpg',\n",
    "    '681100_1959-10-10_2010.jpg'\n",
    "    \n",
    "]\n",
    "\n",
    "sample_contest_face = [\n",
    "    '262800_1943-04-06_2011.jpg',\n",
    "    '102100_1970-10-09_2008.jpg',\n",
    "    '413100_1964-09-14_1994.jpg',\n",
    "    '575600_1979-07-13_2013.jpg',\n",
    "    '634600_1936-10-11_1978.jpg'\n",
    "    \n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9734f1f7e2f0c421",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, _ in enumerate(sample_frontal_face):\n",
    "    if isinstance(sample_frontal_face[i], Path):\n",
    "        continue\n",
    "        \n",
    "    sample_frontal_face[i] = Path(sample_parent + sample_frontal_face[i])\n",
    "    \n",
    "for i, _ in enumerate(sample_profile_face):\n",
    "    if isinstance(sample_profile_face[i], Path):\n",
    "        continue\n",
    "    \n",
    "    sample_profile_face[i] = Path(sample_parent + sample_profile_face[i])\n",
    "    \n",
    "for i, _ in enumerate(sample_contest_face):\n",
    "    if isinstance(sample_contest_face[i], Path):\n",
    "        continue\n",
    "    \n",
    "    sample_contest_face[i] = Path(sample_parent + sample_contest_face[i])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51740a69d123d7d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_cv2 = cv2.imread(str(sample_frontal_face[0]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "305f993846dbfd3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "face_classifier_frontal = cv2.CascadeClassifier(model_frontal)\n",
    "face_classifier_profile = cv2.CascadeClassifier(model_profile)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90b9a3cdae4a6bad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_for_picture(file_name, dataset_name):\n",
    "    image_cv2 = cv2.imread(str(file_name))\n",
    "        \n",
    "    faces_frontal = face_classifier_frontal.detectMultiScale(image_cv2)\n",
    "    faces_profile = face_classifier_profile.detectMultiScale(image_cv2)\n",
    "\n",
    "    # draw bounding box for each face detected\n",
    "    for (x, y, w, h) in faces_frontal:\n",
    "        color = (255,0,0) # red\n",
    "        stroke = 5\n",
    "        cv2.rectangle(image_cv2, (x, y), (x + w, y + h), color, stroke)\n",
    "    \n",
    "    for (x, y, w, h) in faces_profile:\n",
    "        color = (0, 255, 255) # in light blue\n",
    "        stroke = 5\n",
    "        cv2.rectangle(image_cv2, (x, y), (x + w, y + h), color, stroke)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(image_cv2)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    output_path = Path(output_parent) / Path(dataset_name) / Path(file_name).name\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(output_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87ae8dccdd1311bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for image in sample_frontal_face:\n",
    "    detect_for_picture(image, 'frontal_face')\n",
    "    \n",
    "for image in sample_profile_face:\n",
    "    detect_for_picture(image, 'profile_face')\n",
    "\n",
    "for image in sample_contest_face:\n",
    "    detect_for_picture(image, 'contest_face')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb6234ac4ab9055",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process all images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f1aee0b94d17c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_parent = '../data/wiki_crop/'\n",
    "sample_output = '../data/wiki_crop_opencv_position_detection/'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dca85488217c92b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_for_picture_json(file_name):\n",
    "    image_cv2 = cv2.imread(str(file_name))\n",
    "        \n",
    "    faces_frontal = face_classifier_frontal.detectMultiScale(image_cv2)\n",
    "    faces_profile = face_classifier_profile.detectMultiScale(image_cv2)\n",
    "\n",
    "    # draw bounding box for each face detected\n",
    "    faces_frontal = faces_frontal.tolist() if len(faces_frontal) > 0 else []\n",
    "    faces_profile = faces_profile.tolist() if len(faces_profile) > 0 else []\n",
    "    \n",
    "    faces_frontal_result = [[x, y, x + w, y + h] for (x, y, w, h) in faces_frontal]\n",
    "    faces_profile_result = [[x, y, x + w, y + h] for (x, y, w, h) in faces_profile]\n",
    "    \n",
    "    return faces_frontal_result, faces_profile_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49e4d2ab671341b8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "(Path(sample_output) / 'json').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for dataset in Path(sample_parent).iterdir():\n",
    "    detection_result = {}\n",
    "    \n",
    "    images = list(dataset.glob('**/*.jpg'))\n",
    "    for image in tqdm(images):\n",
    "        faces_frontal, faces_profile = detect_for_picture_json(image)\n",
    "        detection_result[image.name] = {\n",
    "            'faces_frontal': faces_frontal,\n",
    "            'faces_profile': faces_profile\n",
    "        }\n",
    "\n",
    "    with open(Path(sample_output) / 'json' / f'{dataset.name}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(detection_result, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7b0be1c211cdab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "864eac499407a76c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
