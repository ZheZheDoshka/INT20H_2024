{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:34.511105Z",
     "start_time": "2024-03-02T13:07:34.489930Z"
    }
   },
   "id": "ce8b7fd0bad997a2",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:34.916051Z",
     "start_time": "2024-03-02T13:07:34.513295Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_frontal = 'model/haarcascade_frontalface_default.xml'\n",
    "model_profile = 'model/haarcascade_profileface.xml'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:34.928717Z",
     "start_time": "2024-03-02T13:07:34.918872Z"
    }
   },
   "id": "c3e6c6965c239d60",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_parent = 'data/wiki_crop/00/'\n",
    "output_parent = 'data/wiki_crop_opencv_position_detection/'\n",
    "\n",
    "sample_frontal_face = [\n",
    "    '69300_1950-05-11_2009.jpg',\n",
    "    '196900_1884-05-20_1940.jpg',\n",
    "    '346200_1968-12-09_2005.jpg',\n",
    "    '487200_1890-12-11_1964.jpg',\n",
    "    '489500_1970-05-05_2006.jpg'\n",
    "]\n",
    "\n",
    "sample_profile_face = [\n",
    "    '23300_1962-06-19_2011.jpg',\n",
    "    '102100_1970-10-09_2008.jpg',\n",
    "    '654800_1950-01-03_1987.jpg',\n",
    "    '681100_1959-10-10_2010.jpg'\n",
    "    \n",
    "]\n",
    "\n",
    "sample_contest_face = [\n",
    "    '262800_1943-04-06_2011.jpg',\n",
    "    '102100_1970-10-09_2008.jpg',\n",
    "    '413100_1964-09-14_1994.jpg',\n",
    "    '575600_1979-07-13_2013.jpg',\n",
    "    '634600_1936-10-11_1978.jpg'\n",
    "    \n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:34.943860Z",
     "start_time": "2024-03-02T13:07:34.931008Z"
    }
   },
   "id": "9734f1f7e2f0c421",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, _ in enumerate(sample_frontal_face):\n",
    "    if isinstance(sample_frontal_face[i], Path):\n",
    "        continue\n",
    "        \n",
    "    sample_frontal_face[i] = Path(sample_parent + sample_frontal_face[i])\n",
    "    \n",
    "for i, _ in enumerate(sample_profile_face):\n",
    "    if isinstance(sample_profile_face[i], Path):\n",
    "        continue\n",
    "    \n",
    "    sample_profile_face[i] = Path(sample_parent + sample_profile_face[i])\n",
    "    \n",
    "for i, _ in enumerate(sample_contest_face):\n",
    "    if isinstance(sample_contest_face[i], Path):\n",
    "        continue\n",
    "    \n",
    "    sample_contest_face[i] = Path(sample_parent + sample_contest_face[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:34.959640Z",
     "start_time": "2024-03-02T13:07:34.946019Z"
    }
   },
   "id": "51740a69d123d7d7",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_cv2 = cv2.imread(str(sample_frontal_face[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:34.974892Z",
     "start_time": "2024-03-02T13:07:34.961206Z"
    }
   },
   "id": "305f993846dbfd3",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "face_classifier_frontal = cv2.CascadeClassifier(model_frontal)\n",
    "face_classifier_profile = cv2.CascadeClassifier(model_profile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:07:35.115993Z",
     "start_time": "2024-03-02T13:07:34.975931Z"
    }
   },
   "id": "90b9a3cdae4a6bad",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_for_picture(file_name, dataset_name):\n",
    "    image_cv2 = cv2.imread(str(file_name))\n",
    "        \n",
    "    faces_frontal = face_classifier_frontal.detectMultiScale(image_cv2)\n",
    "    faces_profile = face_classifier_profile.detectMultiScale(image_cv2)\n",
    "\n",
    "    # draw bounding box for each face detected\n",
    "    for (x, y, w, h) in faces_frontal:\n",
    "        color = (255,0,0) # red\n",
    "        stroke = 5\n",
    "        cv2.rectangle(image_cv2, (x, y), (x + w, y + h), color, stroke)\n",
    "    \n",
    "    for (x, y, w, h) in faces_profile:\n",
    "        color = (0, 255, 255) # in light blue\n",
    "        stroke = 5\n",
    "        cv2.rectangle(image_cv2, (x, y), (x + w, y + h), color, stroke)\n",
    "    \n",
    "    plt.ioff()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(image_cv2)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    output_path = Path(output_parent) / Path(dataset_name) / Path(file_name).name\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:38:46.177223Z",
     "start_time": "2024-03-02T13:38:46.168148Z"
    }
   },
   "id": "87ae8dccdd1311bf",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for image in sample_frontal_face:\n",
    "    detect_for_picture(image, 'frontal_face')\n",
    "    \n",
    "for image in sample_profile_face:\n",
    "    detect_for_picture(image, 'profile_face')\n",
    "\n",
    "for image in sample_contest_face:\n",
    "    detect_for_picture(image, 'contest_face')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:38:47.849955Z",
     "start_time": "2024-03-02T13:38:46.338438Z"
    }
   },
   "id": "deb6234ac4ab9055",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process all images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f1aee0b94d17c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_parent = 'data/wiki_crop/'\n",
    "\n",
    "datasets = [\n",
    "    '00',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:38:53.426506Z",
     "start_time": "2024-03-02T13:38:53.422505Z"
    }
   },
   "id": "9dca85488217c92b",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    sample_path = Path(sample_parent) / Path(dataset)\n",
    "    for image in sample_path.glob('**/*.jpg'):\n",
    "        detect_for_picture(image, dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T13:40:16.154357Z",
     "start_time": "2024-03-02T13:38:53.598314Z"
    }
   },
   "id": "9d7b0be1c211cdab",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "864eac499407a76c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
