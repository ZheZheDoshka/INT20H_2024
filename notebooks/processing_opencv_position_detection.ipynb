{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:06:54.345455Z",
     "start_time": "2024-03-02T14:06:54.316919Z"
    }
   },
   "id": "ce8b7fd0bad997a2",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:07:13.826348Z",
     "start_time": "2024-03-02T14:07:13.819348Z"
    }
   },
   "id": "initial_id",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_frontal = '../models/haarcascade_frontalface_default.xml'\n",
    "model_profile = '../models/haarcascade_profileface.xml'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:11.226506Z",
     "start_time": "2024-03-02T14:09:11.211692Z"
    }
   },
   "id": "c3e6c6965c239d60",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_parent = '../data/wiki_crop/00/'\n",
    "output_parent = '../data/wiki_crop_opencv_position_detection/'\n",
    "\n",
    "sample_frontal_face = [\n",
    "    '69300_1950-05-11_2009.jpg',\n",
    "    '196900_1884-05-20_1940.jpg',\n",
    "    '346200_1968-12-09_2005.jpg',\n",
    "    '487200_1890-12-11_1964.jpg',\n",
    "    '489500_1970-05-05_2006.jpg'\n",
    "]\n",
    "\n",
    "sample_profile_face = [\n",
    "    '23300_1962-06-19_2011.jpg',\n",
    "    '102100_1970-10-09_2008.jpg',\n",
    "    '654800_1950-01-03_1987.jpg',\n",
    "    '681100_1959-10-10_2010.jpg'\n",
    "    \n",
    "]\n",
    "\n",
    "sample_contest_face = [\n",
    "    '262800_1943-04-06_2011.jpg',\n",
    "    '102100_1970-10-09_2008.jpg',\n",
    "    '413100_1964-09-14_1994.jpg',\n",
    "    '575600_1979-07-13_2013.jpg',\n",
    "    '634600_1936-10-11_1978.jpg'\n",
    "    \n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:11.410680Z",
     "start_time": "2024-03-02T14:09:11.406350Z"
    }
   },
   "id": "9734f1f7e2f0c421",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, _ in enumerate(sample_frontal_face):\n",
    "    if isinstance(sample_frontal_face[i], Path):\n",
    "        continue\n",
    "        \n",
    "    sample_frontal_face[i] = Path(sample_parent + sample_frontal_face[i])\n",
    "    \n",
    "for i, _ in enumerate(sample_profile_face):\n",
    "    if isinstance(sample_profile_face[i], Path):\n",
    "        continue\n",
    "    \n",
    "    sample_profile_face[i] = Path(sample_parent + sample_profile_face[i])\n",
    "    \n",
    "for i, _ in enumerate(sample_contest_face):\n",
    "    if isinstance(sample_contest_face[i], Path):\n",
    "        continue\n",
    "    \n",
    "    sample_contest_face[i] = Path(sample_parent + sample_contest_face[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:11.612658Z",
     "start_time": "2024-03-02T14:09:11.603174Z"
    }
   },
   "id": "51740a69d123d7d7",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_cv2 = cv2.imread(str(sample_frontal_face[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:11.983201Z",
     "start_time": "2024-03-02T14:09:11.964259Z"
    }
   },
   "id": "305f993846dbfd3",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "face_classifier_frontal = cv2.CascadeClassifier(model_frontal)\n",
    "face_classifier_profile = cv2.CascadeClassifier(model_profile)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:12.293864Z",
     "start_time": "2024-03-02T14:09:12.185358Z"
    }
   },
   "id": "90b9a3cdae4a6bad",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_for_picture(file_name, dataset_name):\n",
    "    image_cv2 = cv2.imread(str(file_name))\n",
    "        \n",
    "    faces_frontal = face_classifier_frontal.detectMultiScale(image_cv2)\n",
    "    faces_profile = face_classifier_profile.detectMultiScale(image_cv2)\n",
    "\n",
    "    # draw bounding box for each face detected\n",
    "    for (x, y, w, h) in faces_frontal:\n",
    "        color = (255,0,0) # red\n",
    "        stroke = 5\n",
    "        cv2.rectangle(image_cv2, (x, y), (x + w, y + h), color, stroke)\n",
    "    \n",
    "    for (x, y, w, h) in faces_profile:\n",
    "        color = (0, 255, 255) # in light blue\n",
    "        stroke = 5\n",
    "        cv2.rectangle(image_cv2, (x, y), (x + w, y + h), color, stroke)\n",
    "    \n",
    "    plt.ioff()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(image_cv2)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    output_path = Path(output_parent) / Path(dataset_name) / Path(file_name).name\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:41.572838Z",
     "start_time": "2024-03-02T14:09:41.566276Z"
    }
   },
   "id": "87ae8dccdd1311bf",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for image in sample_frontal_face:\n",
    "    detect_for_picture(image, 'frontal_face')\n",
    "    \n",
    "for image in sample_profile_face:\n",
    "    detect_for_picture(image, 'profile_face')\n",
    "\n",
    "for image in sample_contest_face:\n",
    "    detect_for_picture(image, 'contest_face')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:57.609813Z",
     "start_time": "2024-03-02T14:09:56.429040Z"
    }
   },
   "id": "deb6234ac4ab9055",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process all images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7f1aee0b94d17c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_parent = '../data/wiki_crop/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:57.625612Z",
     "start_time": "2024-03-02T14:09:57.610841Z"
    }
   },
   "id": "9dca85488217c92b",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:02, 13.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[52], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m Path(sample_parent)\u001B[38;5;241m.\u001B[39miterdir():\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m tqdm(dataset\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m**/*.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[1;32m----> 3\u001B[0m         \u001B[43mdetect_for_picture\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[46], line 5\u001B[0m, in \u001B[0;36mdetect_for_picture\u001B[1;34m(file_name, dataset_name)\u001B[0m\n\u001B[0;32m      2\u001B[0m image_cv2 \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;28mstr\u001B[39m(file_name))\n\u001B[0;32m      4\u001B[0m faces_frontal \u001B[38;5;241m=\u001B[39m face_classifier_frontal\u001B[38;5;241m.\u001B[39mdetectMultiScale(image_cv2)\n\u001B[1;32m----> 5\u001B[0m faces_profile \u001B[38;5;241m=\u001B[39m \u001B[43mface_classifier_profile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetectMultiScale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_cv2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# draw bounding box for each face detected\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (x, y, w, h) \u001B[38;5;129;01min\u001B[39;00m faces_frontal:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in Path(sample_parent).iterdir():\n",
    "    for image in tqdm(dataset.glob('**/*.jpg')):\n",
    "        detect_for_picture(image, dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:09:59.958122Z",
     "start_time": "2024-03-02T14:09:57.626712Z"
    }
   },
   "id": "9d7b0be1c211cdab",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "864eac499407a76c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
